# v0.31.b.alpha (patch) Release Notes
**Important!**
* `v0.31.b.alpha` is a **patch** release (patch `b` for the `v0.31.alpha` release).

## Purpose
The purpose for this patch release:
1. Remove the invalid guard preventing dynamic ["on-the-fly"](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_on_the_fly_model.html) model engine updates. Support dynamicl model engine updates with a new "update-complete" listener callback function.  
2. Update the "Add IoT Message Meta Action" to add the Trigger name to identify the source of the event. 

## Issues-bugs closed in this release
* The GIE and TIS "config-file-path" and "model-engine-file" properties should be writable in any state [#1295](https://github.com/prominenceai/deepstream-services-library/issues/1295)
*  Add IoT Message Meta Action must add the Trigger Name in the NvDsEventMsgMeta to identify the event source. [#1298](https://github.com/prominenceai/deepstream-services-library/issues/1298)

## Issues-enhancements closed in this release
* Implement dsl_infer_gie_model_update_listener_add/remove services for async model update notifications [#1297](https://github.com/prominenceai/deepstream-services-library/issues/1297)
*  Implement new dynamic "on-the-fly" model-engine update examples using new update-listener callback services. [#1299](https://github.com/prominenceai/deepstream-services-library/issues/1297)

## New Examples in this release
* [dynamically_update_inference_model.py](/examples/python/dynamically_update_inference_model.py)
* [dynamically_update_inference_model.cpp](/examples/cpp/dynamically_update_inference_model.cpp)
